<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>杂项 on IO01 Blog</title><link>/tags/%E6%9D%82%E9%A1%B9/</link><description>Recent content in 杂项 on IO01 Blog</description><generator>Hugo -- gohugo.io</generator><copyright>&amp;copy; {year} &lt;a href="https://blog.io01.xyz/">IO01&lt;/a></copyright><lastBuildDate>Wed, 30 Oct 2019 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E6%9D%82%E9%A1%B9/index.xml" rel="self" type="application/rss+xml"/><item><title>有趣的算法-布隆过滤器</title><link>/posts/%E6%9C%89%E8%B6%A3%E7%9A%84%E7%AE%97%E6%B3%95-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</link><pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate><guid>/posts/%E6%9C%89%E8%B6%A3%E7%9A%84%E7%AE%97%E6%B3%95-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</guid><description>&lt;h2 id="引言">引言&lt;/h2>
&lt;p>现在假设一个需求：设计一个url黑名单系统，需求是1亿个url黑名单，每个url平均长度30字节，判断当前的url是否在黑名单中。&lt;/p>
&lt;p>我们最先想到的可能时HashSet，如果少量的url，HashSet有着O(1)的查询效率是首选的方案。但是面对1亿个url，单单存储value就需要2861MB内存，显然不可取。而如果放到硬盘上进行数据库查询，面对近3GB的数据库，每次匹配都要查询的话，IO操作本身就是瓶颈。&lt;/p>
&lt;p>所以这时候引入了布隆过滤器。&lt;/p></description></item></channel></rss>